{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from spikingjelly.activation_based import neuron,functional,layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:IFNode(\n",
      "  v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch\n",
      "  (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      ") supports for step_mode == 's', which should not be contained by MultiStepContainer!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 3, 8, 8])\n",
      "torch.Size([4, 1, 3, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "net_s=neuron.IFNode(step_mode='s')\n",
    "T = 4\n",
    "N = 1\n",
    "C = 3\n",
    "H = 8\n",
    "W = 8\n",
    "x_seq = torch.rand([T, N, C, H, W])\n",
    "y_seq = functional.multi_step_forward(x_seq, net_s)\n",
    "print(y_seq.shape)\n",
    "\n",
    "net_s.reset()\n",
    "net_m = layer.MultiStepContainer(net_s)\n",
    "z_seq = net_m(x_seq)\n",
    "print(z_seq.shape)\n",
    "\n",
    "# z_seq is identical to y_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 8, 8, 8])\n",
      "torch.Size([4, 1, 8, 8, 8])\n",
      "torch.Size([4, 1, 8, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    T = 4\n",
    "    N = 1\n",
    "    C = 3\n",
    "    H = 8\n",
    "    W = 8\n",
    "    x_seq = torch.rand([T, N, C, H, W])\n",
    "\n",
    "    conv = nn.Conv2d(C, 8, kernel_size=3, padding=1, bias=False)\n",
    "    bn = nn.BatchNorm2d(8)\n",
    "\n",
    "    y_seq = functional.multi_step_forward(x_seq, (conv, bn))\n",
    "    print(y_seq.shape)\n",
    "\n",
    "    net = layer.MultiStepContainer(conv, bn)\n",
    "    z_seq = net(x_seq)\n",
    "    print(z_seq.shape)\n",
    "    # z_seq is identical to y_seq\n",
    "\n",
    "    p_seq = functional.seq_to_ann_forward(x_seq, (conv, bn))\n",
    "    # p_seq.shape = [T, N, 8, H, W]\n",
    "\n",
    "    net = layer.SeqToANNContainer(conv, bn)\n",
    "    q_seq = net(x_seq)\n",
    "    print(q_seq.shape)\n",
    "\n",
    "    # q_seq is identical to p_seq, and also identical to y_seq and z_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ann.state_dict.keys()=odict_keys(['0.weight', '1.weight', '1.bias', '1.running_mean', '1.running_var', '1.num_batches_tracked'])\n",
      "net_container.state_dict.keys()=odict_keys(['0.0.weight', '0.1.weight', '0.1.bias', '0.1.running_mean', '0.1.running_var', '0.1.num_batches_tracked'])\n",
      "net_origin.state_dict.keys()=odict_keys(['0.weight', '1.weight', '1.bias', '1.running_mean', '1.running_var', '1.num_batches_tracked'])\n",
      "net_container is trying to load state dict from ann...\n",
      "net_container can not load! The error message is\n",
      " Error(s) in loading state_dict for Sequential:\n",
      "\tMissing key(s) in state_dict: \"0.0.weight\", \"0.1.weight\", \"0.1.bias\", \"0.1.running_mean\", \"0.1.running_var\". \n",
      "\tUnexpected key(s) in state_dict: \"0.weight\", \"1.weight\", \"1.bias\", \"1.running_mean\", \"1.running_var\", \"1.num_batches_tracked\". \n",
      "net_origin is trying to load state dict from ann...\n",
      "Load success!\n"
     ]
    }
   ],
   "source": [
    "ann = nn.Sequential(\n",
    "    nn.Conv2d(3, 8, kernel_size=3, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(8),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "print(f'ann.state_dict.keys()={ann.state_dict().keys()}')\n",
    "\n",
    "net_container = nn.Sequential(\n",
    "    layer.SeqToANNContainer(\n",
    "        nn.Conv2d(3, 8, kernel_size=3, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(8),\n",
    "    ),\n",
    "    neuron.IFNode(step_mode='m')\n",
    ")\n",
    "print(f'net_container.state_dict.keys()={net_container.state_dict().keys()}')\n",
    "\n",
    "net_origin = nn.Sequential(\n",
    "    layer.Conv2d(3, 8, kernel_size=3, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(8),\n",
    "    neuron.IFNode(step_mode='m')\n",
    ")\n",
    "print(f'net_origin.state_dict.keys()={net_origin.state_dict().keys()}')\n",
    "\n",
    "try:\n",
    "    print('net_container is trying to load state dict from ann...')\n",
    "    net_container.load_state_dict(ann.state_dict())\n",
    "    print('Load success!')\n",
    "except BaseException as e:\n",
    "    print('net_container can not load! The error message is\\n', e)\n",
    "\n",
    "try:\n",
    "    print('net_origin is trying to load state dict from ann...')\n",
    "    net_origin.load_state_dict(ann.state_dict())\n",
    "    print('Load success!')\n",
    "except BaseException as e:\n",
    "    print('net_origin can not load! The error message is', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net.step_mode=s\n",
      "torch.Size([4, 2, 4, 8, 8])\n",
      "torch.Size([2, 4, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    T = 4\n",
    "    N = 2\n",
    "    C = 4\n",
    "    H = 8\n",
    "    W = 8\n",
    "    x_seq = torch.rand([T, N, C, H, W])\n",
    "    net = layer.StepModeContainer(\n",
    "        False,\n",
    "        nn.Conv2d(C, C, kernel_size=3, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(C),\n",
    "    )\n",
    "    print(f'net.step_mode={net.step_mode}')\n",
    "    net.step_mode = 'm'\n",
    "    y_seq = net(x_seq)\n",
    "    print(y_seq.shape)\n",
    "    # y_seq.shape = [T, N, C, H, W]\n",
    "\n",
    "    net.step_mode = 's'\n",
    "    y = net(x_seq[0])\n",
    "    print(y.shape)\n",
    "    # y.shape = [N, C, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:IFNode(\n",
      "  v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch\n",
      "  (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      ") supports for step_mode == 's', which should not be contained by StepModeContainer!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net.step_mode=m\n",
      "net[0].step_mode=s\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    net = layer.StepModeContainer(\n",
    "        True,\n",
    "        neuron.IFNode()\n",
    "    )\n",
    "    functional.set_step_mode(net, 'm')\n",
    "    print(f'net.step_mode={net.step_mode}')\n",
    "    print(f'net[0].step_mode={net[0].step_mode}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51582ed516be4194d0681ab41331bdf49015ae552f1f95522fcb6a8efc2a378b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
