{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tanghao/miniconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import argparse, os, sys,time\n",
    "from typing import Callable, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(T=100, b=64, data_dir='/data/tanghao/datasets/', device='cuda:0', epochs=1, j=4, lr=0.001, momentum=0.9, opt='adam', tau=2.0)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='STDP learning')\n",
    "parser.add_argument('-T', default=100, type=int, help='simulating time-steps')\n",
    "parser.add_argument('-device', default='cuda:0', help='device')\n",
    "parser.add_argument('-b', default=64, type=int, help='batch size')\n",
    "parser.add_argument('-epochs', default=1, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('-j', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('-data-dir', default='/data/tanghao/datasets/', type=str, help='root dir of dataset')\n",
    "parser.add_argument('-opt', type=str, choices=['sgd', 'adam'], default='adam', help='use which optimizer. SGD or Adam')\n",
    "parser.add_argument('-momentum', default=0.9, type=float, help='momentum for SGD')\n",
    "parser.add_argument('-lr', default=1e-3, type=float, help='learning rate')\n",
    "parser.add_argument('-tau', default=2.0, type=float, help='parameter tau of LIF neuron')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "print(args)\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=args.data_dir,\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=args.data_dir,\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "train_data_loader = data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=args.b,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=args.j,\n",
    "    pin_memory=True\n",
    ")\n",
    "test_data_loader = data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=args.b,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=args.j,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[0][0].shape)\n",
    "print(test_dataset[0][0].device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设像素密度为$\\lambda$，$N(\\Delta t)\\sim P(\\lambda \\Delta t)$，则$\\Delta t$时刻后发射脉冲的概率为$P(N(\\Delta t)=1)=\\lambda \\Delta t(e^{-\\lambda \\Delta t})\\approx \\lambda \\Delta t+o(\\Delta t)$\n",
    "因此在$\\Delta t$时刻后发射脉冲的概率正比像素密度，设$x\\sim U(0,1)$，则$P(N(\\Delta t)=1)=P(x<\\lambda \\Delta t)=\\lambda \\Delta t$，由此，可以使用代码实现为`torch.rand_like(x).le(x)`。\n",
    "    <!-- def spike_generator(self, rate, dt):\n",
    "        return np.random.uniform(0, 1, size=rate.shape) < rate * dt -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Possion_Encoder(x):\n",
    "    return torch.rand_like(x).le(x).to(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "          1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "          1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "          1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "print(Possion_Encoder(test_dataset[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_update(ops,x,mem,tau,spike):\n",
    "    mem=mem*tau*(1-spike)+ops(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActFun(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.gt(0).float()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input < 0] = 0\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LIFNeuron(nn.Module):\n",
    "#     def __init__(self, tau=2.0,v_threshold=1.0, v_reset=0.0,soft_reset=True):\n",
    "#         super(LIFNeuron, self).__init__()\n",
    "#         self.tau = tau\n",
    "#         self.v = None\n",
    "#         self.s = None\n",
    "#         self.v_threshold = v_threshold\n",
    "#         self.v_reset = v_reset\n",
    "#         self.soft_reset=soft_reset\n",
    "\n",
    "#     def reset(self):\n",
    "#         self.v = None\n",
    "#         self.s = None\n",
    "    \n",
    "#     def charge(self, x):\n",
    "#         if self.v is None:\n",
    "#             self.v = torch.zeros_like(x)\n",
    "#             self.s = torch.zeros_like(x)\n",
    "#         self.v = self.v + (1.0 - self.v) / self.tau * x\n",
    "\n",
    "#         return self\n",
    "\n",
    "#     def spike(self):\n",
    "#         if self.soft_reset:\n",
    "#             self.v = self.v * (self.v < self.v_threshold).float() + self.v_reset * (self.v >= self.v_threshold).float()\n",
    "#         else:\n",
    "#             self.v=self.v*(self.v<self.v_threshold)\n",
    "#         return (self.v >= self.v_threshold).to(self.v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIFNeuron(nn.Module):\n",
    "    def __init__(self, tau=2.0, v_threshold=1.0, v_reset=0.0, soft_reset=True):\n",
    "        super(LIFNeuron, self).__init__()\n",
    "        self.tau = tau\n",
    "        self.v = None\n",
    "        self.s = None\n",
    "        self.v_threshold = v_threshold\n",
    "        self.v_reset = v_reset\n",
    "        self.soft_reset = soft_reset\n",
    "\n",
    "    def reset(self):\n",
    "        self.v = None\n",
    "        self.s = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.v is None:\n",
    "            self.v = torch.zeros_like(x)\n",
    "            self.s = torch.zeros_like(x)\n",
    "        self.v = self.v + (1.0 - self.v) / self.tau * x\n",
    "        spike = (self.v >= self.v_threshold).to(x)\n",
    "        if self.soft_reset:\n",
    "            self.v = self.v-self.v_threshold*spike\n",
    "        else:\n",
    "            self.v = self.v * (1-spike) + self.v_reset * spike\n",
    "\n",
    "        return (self.v >= self.v_threshold).to(self.v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Linear_Spiking(nn.Module):\n",
    "#     def __init__(self, N_in, N_out, tau=2.0, v_threshold=1.0, v_reset=0.0, soft_reset=True):\n",
    "#         super(Linear_Spiking, self).__init__()\n",
    "#         self.prototype = nn.Sequential(\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(N_in, N_out,bias=False)\n",
    "#         )\n",
    "#         self.lif = LIFNeuron(tau=tau, v_threshold=v_threshold,\n",
    "#                              v_reset=v_reset, soft_reset=soft_reset)\n",
    "        \n",
    "\n",
    "#     def reset(self):\n",
    "#         self.lif.reset()\n",
    "        \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.prototype(x)\n",
    "#         y = self.lif.charge(x).spike()\n",
    "#         return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "tr_{pre}[i][t]=tr_{pre}[i][t]-\\frac{tr_{pre}[i][t-1]}{\\tau_{pre}}+s[i][t]\\\\\n",
    "tr_{post}[j][t]=tr_{post}[j][t]-\\frac{tr_{post}[j][t-1]}{\\tau_{post}}+s[j][t]\\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Delta W[i][j][t]=F_{post}(w[i][j][t])\\cdot tr_{pre}[i][t]\\cdot s[j][t]-F_{pre}(w[i][j][t])\\cdot tr_{post}[j][t]\\cdot s[i][t]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdp_linear_single_step(\n",
    "    fc: nn.Linear, in_spike: torch.Tensor, out_spike: torch.Tensor,\n",
    "    trace_pre: Union[float, torch.Tensor, None],\n",
    "    trace_post: Union[float, torch.Tensor, None],\n",
    "    tau_pre: float, tau_post: float, w_min: float, w_max: float,\n",
    "    f_pre: Callable = lambda x: x, f_post: Callable = lambda x: x\n",
    "):\n",
    "    if trace_pre is None:\n",
    "        trace_pre = 0.\n",
    "\n",
    "    if trace_post is None:\n",
    "        trace_post = 0.\n",
    "\n",
    "    weight = fc.weight.data\n",
    "    trace_pre = trace_pre - trace_pre / tau_pre + in_spike      # shape = [batch_size, N_in]\n",
    "    trace_post = trace_post - trace_post / tau_post + out_spike # shape = [batch_size, N_out]\n",
    "\n",
    "    # [batch_size, N_out, N_in] -> [N_out, N_in]\n",
    "    # 此处对照更新公式，使用unsqueeze添加更新公式中所缺失的一维\n",
    "    delta_w_pre = -f_pre(weight, w_min) * (trace_post.unsqueeze(2) * in_spike.unsqueeze(1)).sum(0)\n",
    "    delta_w_post = f_post(weight, w_max) * (trace_pre.unsqueeze(1) * out_spike.unsqueeze(2)).sum(0)\n",
    "    return trace_pre, trace_post, delta_w_pre + delta_w_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_Spiking(nn.Module):\n",
    "    def __init__(self, N_in, N_out, tau=2.0, v_threshold=1.0, v_reset=0.0, soft_reset=True):\n",
    "        super(Linear_Spiking, self).__init__()\n",
    "        self.lif = LIFNeuron(tau=tau, v_threshold=v_threshold,\n",
    "                             v_reset=v_reset, soft_reset=soft_reset)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(N_in, N_out, bias=False),\n",
    "            LIFNeuron(tau=tau, v_threshold=v_threshold,\n",
    "                      v_reset=v_reset, soft_reset=soft_reset)\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.lif.reset()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.net(x)\n",
    "        if self.synapse.weight.grad is None:\n",
    "            self.synapse.weight.grad = -delta_w\n",
    "        else:\n",
    "            self.synapse.weight.grad = self.synapse.weight.grad - delta_w\n",
    "        # if on_grad:\n",
    "        #     if self.synapse.weight.grad is None:\n",
    "        #         self.synapse.weight.grad = -delta_w\n",
    "        #     else:\n",
    "        #         self.synapse.weight.grad = self.synapse.weight.grad - delta_w\n",
    "        # else:\n",
    "        #     return delta_w\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class weight_update(nn.Module):\n",
    "    def __init__(self, synapse, tau_pre, tau_post, w_min, w_max, f_pre, f_post):\n",
    "        super(weight_update, self).__init__()\n",
    "        self.synapse = synapse\n",
    "        self.tau_pre = tau_pre\n",
    "        self.tau_post = tau_post\n",
    "        self.w_min = w_min\n",
    "        self.w_max = w_max\n",
    "        self.f_pre = f_pre\n",
    "        self.f_post = f_post\n",
    "        self.trace_pre = None\n",
    "        self.trace_post = None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Linear_Spiking(784,10)\n",
    "# if args.opt == 'adam':\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "model=model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n"
     ]
    }
   ],
   "source": [
    "for item in model.parameters():\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     20\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(out_fr, label_onehot)\n\u001b[0;32m---> 21\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     22\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     24\u001b[0m train_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mnumel()\n",
      "File \u001b[0;32m/data/tanghao/miniconda3/envs/py38/lib/python3.8/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/data/tanghao/miniconda3/envs/py38/lib/python3.8/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    155\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    156\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "acc_max = 0\n",
    "epoch_max = 0\n",
    "for epoch in range(args.epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    train_samples = 0\n",
    "    model.train()\n",
    "    for imag, label in train_data_loader:\n",
    "        imag = imag.to(args.device)\n",
    "        label = label.to(args.device)\n",
    "        label_onehot = F.one_hot(label, 10)\n",
    "        out_fr = 0.\n",
    "        for t in range(args.T):\n",
    "            imag_possion = Possion_Encoder(imag)\n",
    "            out_fr += model(imag_possion)\n",
    "\n",
    "        out_fr = out_fr / args.T\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.mse_loss(out_fr, label_onehot)\n",
    "        \n",
    "        # loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_samples += label.numel()\n",
    "        train_loss += loss.item() * label.numel()\n",
    "        train_acc += (out_fr.argmax(1) == label).float().sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51582ed516be4194d0681ab41331bdf49015ae552f1f95522fcb6a8efc2a378b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
